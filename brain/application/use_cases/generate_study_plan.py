import sys
import asyncio
import logging
from types import SimpleNamespace
from uuid import UUID, uuid4
from typing import List, Dict
from datetime import datetime, timezone
from dataclasses import replace

from brain.domain.services.study_plan_generator import StudyPlanGenerator
from brain.domain.policies.adaptive_rule import AdaptiveRule
from brain.config.settings import Settings
from brain.application.ports.repositories import (
    StudentRepository,
    PerformanceRepository,
    KnowledgeRepository,
    StudyPlanRepository,
    CognitiveProfileRepository,
    KnowledgeVectorRepository,
)
from brain.application.ports.ai_service import AIService
from brain.application.dto.study_plan_dto import (
    StudyPlanDTO,
    StudySessionDTO,
    StudyItemDTO,
    StudyPlanOutputDTO,
)
from brain.application.services.roi_analysis_service import ROIAnalysisService
from brain.application.services.memory_analysis_service import MemoryAnalysisService


# Configura√ß√£o do Logger
logger = logging.getLogger(__name__)

class StudentNotFoundError(Exception):
    pass
class CognitiveProfileNotFoundError(Exception):
    pass

class GenerateStudyPlanUseCase:
    def __init__(
        self,
        student_repo: StudentRepository,
        performance_repo: PerformanceRepository,
        knowledge_repo: KnowledgeRepository,
        study_plan_repo: StudyPlanRepository,
        cognitive_profile_repo: CognitiveProfileRepository,
        vector_repo: KnowledgeVectorRepository = None,
        ai_service: AIService = None,
        adaptive_rules: List[AdaptiveRule] = None,
        settings: Settings = None,
    ):
        self.student_repo = student_repo
        self.performance_repo = performance_repo
        self.knowledge_repo = knowledge_repo
        self.study_plan_repo = study_plan_repo
        self.cognitive_profile_repo = cognitive_profile_repo
        self.vector_repo = vector_repo
        self.ai_service = ai_service
        self.adaptive_rules = adaptive_rules or []
        self.memory_service = MemoryAnalysisService()
        self.roi_service = ROIAnalysisService()
        # Configura√ß√£o de fallback controlado: em testes antigos onde n√£o se passa
        # Settings, permitimos o fallback falso por compatibilidade. Em produ√ß√£o,
        # passe um `Settings` com `ALLOW_FAKE_FALLBACK=False` para fail-fast.
        if settings is None:
            self.allow_fake_fallback = True
        else:
            self.allow_fake_fallback = bool(getattr(settings, 'ALLOW_FAKE_FALLBACK', False))

    async def execute(self, student_id: UUID) -> StudyPlanDTO:
        logger.info(f"--- [PLAN-FLOW] üèÅ Iniciando gera√ß√£o de plano para {student_id} ---")
        try:
            # 1. Recupera√ß√£o de Contexto
            student = await self.student_repo.get_by_id(student_id)
            if not student:
                raise StudentNotFoundError(f"Estudante {student_id} n√£o encontrado.")
            
            profile = await self.cognitive_profile_repo.get_by_student_id(student_id)
            if not profile:
                raise CognitiveProfileNotFoundError(f"Perfil cognitivo do estudante {student_id} n√£o encontrado.")
            recent_events = await self.performance_repo.get_recent_events(student_id)
            all_nodes = await self.knowledge_repo.get_full_graph()
            
            # 2. Calcular reten√ß√£o de todos os n√≥s estudados
            logger.info("[PLAN-FLOW] Calculando reten√ß√£o atual (Ebbinghaus)...")
            node_retention_map: Dict[str, float] = {}
            for node in all_nodes:
                last_review = getattr(node, "last_review", getattr(node, "last_reviewed_at", None))
                if last_review:
                    retention = self.memory_service.calculate_retention_probability(
                        last_review,
                        node.stability
                    )
                    node_retention_map[str(node.id)] = retention
                else:
                    node_retention_map[str(node.id)] = 0.0

            # 3. Executar regras adaptativas no perfil cognitivo
            logger.info("[PLAN-FLOW] Aplicando regras adaptativas...")
            for rule in self.adaptive_rules:
                rule.apply(profile, recent_events)
            
            # Capturar focus_level ap√≥s regras (pode ter mudado para RECOVERY)
            focus_level_after_rules = profile.focus_level
            logger.info(f"[PLAN-FLOW] Focus Level ap√≥s regras: {focus_level_after_rules}")

            # 4. Calcular node_scores (ROI * (1 - retention))
            logger.info("[PLAN-FLOW] Calculando scores de prioriza√ß√£o...")
            performance_map = {
                str(event.node_id): event.score / 100.0 
                for event in recent_events
            }
            
            node_scores: Dict[str, float] = {}
            for node in all_nodes:
                proficiency = performance_map.get(str(node.id), 0.0)
                roi_score = self.roi_service.calculate_priority_score(node, proficiency)
                retention = node_retention_map.get(str(node.id), 0.0)
                
                # F√≥rmula: roi_score * (1 - retention)
                priority_score = roi_score * (1.0 - retention)
                node_scores[str(node.id)] = priority_score

            # 5. Gerar plano usando o novo generator com node_scores
            logger.info("[PLAN-FLOW] Gerando plano de estudo com scores customizados...")
            generator = StudyPlanGenerator(
                knowledge_graph_data=all_nodes,
                roi_service=self.roi_service,
                memory_service=self.memory_service
            )
            
            study_plan = generator.generate(
                student=student,
                cognitive_profile=profile,
                performance_events=recent_events,
                node_scores=node_scores
            )

            # 6. Determinar estrat√©gia e goal baseado no focus_level (n√£o mutamos o objeto retornado pelo generator)
            plan_focus = getattr(study_plan, 'focus_level', focus_level_after_rules)
            if plan_focus == "RECOVERY" or (hasattr(plan_focus, 'value') and plan_focus.value == "RECOVERY"):
                plan_goal = "Recupera√ß√£o de Mem√≥ria e Descanso Ativo"
                logger.info(f"[PLAN-FLOW] MODO RECUPERA√á√ÉO: {len(getattr(study_plan, 'knowledge_nodes', []))} n√≥s de revis√£o emergencial.")
            else:
                plan_goal = "Avan√ßo Estrat√©gico com Revis√£o"
                logger.info(f"[PLAN-FLOW] MODO APRENDIZADO: {len(getattr(study_plan, 'knowledge_nodes', []))} n√≥s selecionados.")

            # Mantemos o objeto `study_plan` retornado pelo generator intacto (testes esperam isso)

            # 8. Gerar conte√∫do via IA (Mantendo o RAG e Retries) ‚Äî protegido quando n√£o h√° servi√ßos injetados
            logger.info(f"[PLAN-FLOW] Gerando conte√∫do para {len(study_plan.knowledge_nodes)} n√≥s selecionados...")
            generated_cards = []
            for i, node in enumerate(study_plan.knowledge_nodes):
                node_name = getattr(node, 'name', str(node))
                node_difficulty = getattr(node, 'difficulty', getattr(node, 'difficulty', 5))
                logger.info(f"--- [PLAN-FLOW] Processando N√≥ {i+1}/{len(study_plan.knowledge_nodes)}: '{node_name}' ---")

                # Prote√ß√µes para evitar falha em ambientes de teste sem servi√ßos externos
                if not self.vector_repo or not self.ai_service:
                    if self.allow_fake_fallback:
                        logger.warning(
                            "[PLAN-FLOW] Ambiente sem servi√ßos de IA injetados: usando fallback de cards simples. "
                            "Verifique configura√ß√µes de `GEMINI_API_KEY`/`GROQ_API_KEY` em produ√ß√£o."
                        )
                        generated_cards.append({
                            "pergunta": f"Quest√£o sobre: {node_name}",
                            "opcoes": ["A", "B", "C", "D"],
                            "correta_index": 0,
                            "explicacao": "Explica√ß√£o autom√°tica indispon√≠vel em ambiente de teste."
                        })
                        continue
                    else:
                        raise RuntimeError("AI services unavailable and fake fallback is disabled (FAIL_FAST).")

                try:
                    rag_context = await self.vector_repo.search_context(query=node.name, limit=1)
                except Exception:
                    rag_context = None

                final_context = rag_context if rag_context else f"Conceitos de {node.name}"

                try:
                    card = await self.ai_service.generate_flashcard(
                        topic=node_name,
                        difficulty=int(node_difficulty * 5),
                        context=final_context
                    )
                    generated_cards.append(card)
                except Exception as e:
                    logger.error(f"FALHA NA IA para '{node.name}', usando fallback: {e}")
                    generated_cards.append({
                        "pergunta": f"Quest√£o sobre: {node.name}",
                        "opcoes": ["A", "B", "C", "D"],
                        "correta_index": 0,
                        "explicacao": "A IA falhou. Use este card para estudo manual."
                    })

                if i < len(study_plan.knowledge_nodes) - 1:
                    await asyncio.sleep(0.01) # Pausa curta em teste

            # 9. Persist√™ncia do Plano
            await self.study_plan_repo.save(study_plan)
            logger.info("[PLAN-FLOW] Plano de estudo salvo no banco.")

            # 10. Formata√ß√£o do DTO de resposta
            return self._format_dto(study_plan, student.id, generated_cards, focus_level_after_rules)

        except Exception as e:
            logger.critical(f"[PLAN-FLOW] üíÄ CRITICAL ERROR: {e}", exc_info=True)
            raise e

    def _format_dto(self, study_plan, student_id, generated_cards, focus_level) -> StudyPlanDTO:
        logger.info("[PLAN-FLOW] Formatando resposta (DTO)...")
        sessions_dto = []
        
        # Convers√£o segura: se focus_level for um Enum, extrair o valor; caso contr√°rio, usar como string
        if hasattr(focus_level, 'value'):
            focus_level_str = focus_level.value
        else:
            focus_level_str = str(focus_level)

        # Se quisermos compatibilidade com testes que esperam um DTO simplificado,
        # retornamos um `StudyPlanOutputDTO` com os campos essenciais.
        knowledge_nodes_list = [
            getattr(n, 'id', n) for n in getattr(study_plan, 'knowledge_nodes', [])
        ]

        estimated_duration = getattr(study_plan, 'estimated_duration_minutes', 0)
        logger.info("[PLAN-FLOW] üéâ Plano gerado e entregue com sucesso!")

        return StudyPlanOutputDTO(
            id=study_plan.id,
            student_id=student_id,
            knowledge_nodes=knowledge_nodes_list,
            created_at=getattr(study_plan, 'created_at', datetime.now(timezone.utc)),
            estimated_duration_minutes=estimated_duration,
            focus_level=focus_level_str,
            flashcards=generated_cards,
        )